# Toxic-Comment-Classification-Challenge
Попытка решить задачу детектирования "плохих" комментариев без использования эмбеддингов

Комментарии по устройству классификатора внутри .ipynb файла

Небольшой тчет:
1. Какая	получилась	точность	у	модели?
по целевой метрике roc_auc = 0.885

2. Какие	есть	способы	ускорения/уменьшения	модели?
Куда уж меньше) вся масса модели содержится в нескольких словарях размер которых ограничивается десятками тысяч слов.
Уменьшить эти словари можно, изменяя параметры min_board. Так, даже обрезав слова которые во всей выборке встретились один раз, можно уменьшить размер словарей почти вдвое.
Работает обученная модель тоже быстро, но вот качество предсказаний посредственное (хотя мне казалось, что будет хуже).
Большая часть возможностей для улучшения модели сосредоточилась в придумывании более информативных индексов комментария, и более обдуманному составлению словаря.

3. Как	выбрать	баланс	между	качеством	и	скоростью?
Зависит от ресурсов и специфики задачи

4. Что	 лучше	 — тяжелая	 модель	 и	 потом	 ее	 оптимизировать	 или	 сразу	
легкая?
Открытый вопрос

5. Опишите ваш	подход.	Чем	он	лучше	других	возможных	подходов?	Какие	
у	него	могут	быть	недостатки?
Главное преимущесво - простота модели. Она быстрая и легкая.
Второе, это интерпретируемость индексов комментария, которой нет у эмбедингов. Если подумать, возможно, можно придумать еще какие-то информативные индексы.

6. Что	можно	сделать,	чтобы	улучшить	классификатор?
Думать в сторону улучшения индесов и словаря. Например подсчет колличества местоимений или обращений.
